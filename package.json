{
  "name": "local-ai-assistant",
  "displayName": "Local-AI-Assistant",
  "description": "A VS Code extension that interacts with a LLM API endpoint on your network",
  "publisher": "officedrone",
  "icon": "media/icon.png",
  "version": "0.0.16",
  "repository": {
    "type": "git",
    "url": "https://github.com/officedrone/local-ai-assistant"
  },
  "bugs": {
    "url": "https://github.com/officedrone/local-ai-assistant/issues"
  },
  "engines": {
    "vscode": ">=1.90.0"
  },
  "categories": [
    "Programming Languages",
    "Linters",
    "Snippets",
    "AI",
    "Chat",
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./out/extension.js",
    "files": [
    "out/",
    "src/static/css/",
    "src/static/webviewScripts/",
    "src/handlers/chatPanel/",
    "media/",
    "package.json",
    "README.md",
    "LICENSE.md"
  ],
  "contributes": {
    "commands": [
      {
        "command": "extension.completeCurrentLine",
        "title": "Complete Code",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.openChatPanel",
        "title": "Open Chat",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.validateCodeAction",
        "title": "Validate Code",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.openSettingsPanel",
        "title": "Open Settings",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.setApiKey",
        "title": "Set API Key",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.selectModel",
        "title": "Select Model",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.selectApiType",
        "title": "Select Api Type",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.setApiURL",
        "title": "Set LLM API endpoint URL",
        "category": "Local AI Assistant"
      },
      {
        "command": "extension.setContextSize",
        "title": "Set Context Size",
        "category": "Local AI Assistant"
      }

    ],
    "keybindings": [
      {
        "command": "extension.selectModel",
        "key": "ctrl+shift+alt+m",
        "mac": "cmd+shift+alt+m"
      },
      {
        "command": "extension.completeCurrentLine",
        "key": "ctrl+shift+alt+enter",
        "mac": "cmd+shift+alt+enter"
      },
      {
        "command": "extension.openChatPanel",
        "key": "ctrl+shift+alt+c",
        "mac": "cmd+shift+alt+c"
      },
      {
        "command": "extension.validateCodeAction",
        "key": "ctrl+shift+alt+v",
        "mac": "cmd+shift+alt+v"
      },
      {
        "command": "extension.setApiKey",
        "key": "ctrl+shift+alt+k",
        "mac": "cmd+shift+alt+k"
      },
      {
        "command": "extension.selectApiType",
        "key": "ctrl+shift+alt+a",
        "mac": "cmd+shift+alt+a"
      },
      {
        "command": "extension.setApiURL",
        "key": "ctrl+shift+alt+u",
        "mac": "cmd+shift+alt+u"
      },
      {
        "command": "extension.setContextSize",
        "key": "ctrl+shift+alt+z",
        "mac": "cmd+shift+alt+z"
      }

    ],
    "submenus": [
      {
        "id": "localAI.submenu",
        "label": "Local AI Assistant"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "submenu": "localAI.submenu",
          "group": "LocalAIAssistant@1"
        }
      ],
      "localAI.submenu": [
        {
          "command": "extension.openChatPanel"
        },
        {
          "command": "extension.validateCodeAction"
        },
        {
          "command": "extension.completeCurrentLine"
        }
      ]
    },
    "configuration": {
      "title": "Local AI Assistant",
      "properties": {
        "localAIAssistant.apiLLM.config.apiType": {
          "type": "string",
          "enum": [
            "OpenAI",
            "Ollama"
          ],
          "default": "OpenAI",
          "description": "Choose the type of API to interact with — OpenAI or Ollama (upcoming – not supported yet)."
        },
        "localAIAssistant.apiLLM.apiURL.endpoint": {
          "type": "string",
          "default": "http://localhost:1234/v1",
          "description": "Endpoint URL for your local LLM API (HINT: OpenAI URLs end in /v1, Ollama URLs end in /api)."
        },
        "localAIAssistant.apiLLM.config.apiAuthRequired": {
          "type": "boolean",
          "default": false,
          "description": "(Optional unless your service requires it) Press `Ctrl+Shift+Alt+K` to securely enter your key via the Command Palette."
        },
        "localAIAssistant.apiLLM.config.model": {
          "type": "string",
          "default": "",
          "description": "(Optinal unless your service requires it) Model to use for completions and chat requests. If you are not sure of the model you can try select a model your service supports by pressing CTRL+SHIFT+ALT+M (CTL+SHIFT+ALT+M on Mac)"
        },
        "localAIAssistant.context.contextSize": {
          "type": "number",
          "default": 4096,
          "description": "AI model Context limit (in tokens) - Match this number to your LLM service context number for best results"
        },
        "localAIAssistant.tooltop.enableExtensionTooltip": {
          "type": "boolean",
          "default": true,
          "description": "Enable extension tooltip in the main code editor"
        },
        "localAIAssistant.tooltip.idleTooltipDelay": {
          "type": "number",
          "default": 1500,
          "minimum": 500,
          "description": "Delay in milliseconds before showing the auto-complete tooltip."
        },
        "localAIAssistant.context.includeFileContext": {
          "type": "boolean",
          "default": true,
          "description": "Include the active editor text as context."
        }
      }
    }
  },
  "dependencies": {
    "axios": "^1.4.0",
    "gpt-tokenizer": "^3.0.1"
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src",
    "test": "vscode-test"
  },
  "devDependencies": {
    "@types/node": "20.x",
    "@types/vscode": "^1.90.0",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "@vscode/test-cli": "^0.0.11",
    "eslint": "^9.25.1",
    "typescript": "^5.8.3"
  }
}